%!TEX program = xelatex 
% 告诉 texstudio， 无论默认编译器什么设置， 本 tex 文档都采用 xelatex 编译
% "C:/software/texlive/2016/bin/win32/xelatex.exe" -synctex=1 -interaction=nonstopmode %.tex
% 参考：https://github.com/YimianDai/iNSFC
\documentclass[a4paper,zihao=-4]{article}
\usepackage[UTF8,punct,linespread=1.56]{ctex}
% \documentclass[a4paper,cs4size,UTF8,punct,linespread=1.56]{ctexart}
\pagestyle{empty} % 第二页以后页码空白
\usepackage[a4paper, left = 3.2cm, right = 3.2cm, top = 2.54cm, bottom = 2.54cm]{geometry}
\usepackage{xcolor}
% \usepackage[citebordercolor = white]{hyperref}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{times}
\usepackage[subrefformat=parens,labelformat=parens]{subfig} %
\usepackage{booktabs} % for \toprule \midrule \bottomrule \cmidrule
\usepackage{cleveref}
\crefformat{table}{表~#2#1#3}
\crefformat{figure}{图~#2#1#3}
\crefformat{equation}{式~（#2#1#3）}
\usepackage{enumitem}
% \setenumerate[1]{itemsep = 0pt, parsep = 0pt, topsep = 2bp}
\setlist[enumerate]{itemsep = 0pt, parsep = 0pt, topsep = 2bp}
% \setitemize[1]{itemsep = 0pt, parsep = 0pt, topsep = 2bp}
\setlist[itemize]{itemsep = 0pt, parsep = 0pt, topsep = 2bp}
\usepackage{fontspec}
\setmainfont{Times New Roman}
% \usepackage{minted}   % For syntax highlighting
% \usemintedstyle{friendly}
\usepackage{setspace} 
\usepackage{caption}
\DeclareCaptionFont{capfont}{\kaishu\zihao{-4}\selectfont} % Caption font
\DeclareCaptionFont{subfont}{\kaishu\zihao{5}\selectfont} % Sub-caption font
\captionsetup{font = capfont}
\captionsetup[subfigure]{font = subfont}
\captionsetup[figure]{labelsep=space} % 空格 space；点 period；冒号 colon
\captionsetup[table]{labelsep=space}  % 空格 space；点 period；冒号 colon
\usepackage[square,numbers,sort&compress]{natbib}   % For Reference
\newcommand{\citess}[1]{\textsuperscript{\cite{#1}}}
\setlength{\bibsep}{1pt plus 0.3ex}
\usepackage{titlesec}
\titleformat{\subsubsection}[block]{\hspace{3em}}{\thesubsubsection}{1em}{}
\usepackage{insfc}



\graphicspath{{images/}}   % 设置图片所存放的目录

\begin{document}

\kaishu

% Decrease space above and below equations
\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{0pt}

%%%%%%%%% TITLE %%%%%%%%%
% \title{报告正文 \vspace{-3.4ex}}
% \title{报告正文}
% \maketitle
\begin{center}
	{\kaishu \zihao{2} \textbf{报告正文} \vspace{-3ex}}
\end{center}  

\thispagestyle{empty} 　　　% 首页页码空白

%%%%%%%%% Your Content %%%%%%%%%
%{\kaishu \zihao{4}参照以下提纲撰写，要求内容翔实、清晰，层次分明，标题突出。}\alert{请勿删除或改动下述提纲标题及括号中的文字。\vspace{9bp}}

\NsfcChapter{（一）立项依据与研究内容}{（4000-8000字）：}

\NsfcSection{1}{项目的立项依据}{（研究意义、国内外研究现状及发展动态分析，需结合科学研究发展趋势来论述科学意义；或结合国民经济和社会发展中迫切需要解决的关键科技问题来论述其应用前景。附主要参考文献目录）；}

\subsection{研究意义}
近年来，人工智能经历了迅猛的发展并且深刻地改变着人类社会和生活的方方面面。世界上的众多发达国家都将发展人工智能作为增强国家综合实力、提高先进科技竞争力和维护国家安全与稳定的重大战略方案[1]。2016年10月，美国国家科学技术委员会（NSTC）先后公布了《Preparing for the Future of Artificial Intelligence》（为人工智能的未来做好准备）和《National Artificial Intelligence Research and Development Strategic Plan》（国家人工智能研究与发展战略计划）两份重要报告，阐述了美国政府重点发展人工智能的战略决策与相关建议[2]。2017年7月，中国国务院也颁布了《新一代人工智能发展规划》，重点介绍了我国政府发展新一代人工智能的战略目标和主要任务，指明了构建世界一流科技强国的重要方向[3]。此外，中国科技部也在2018年10月开始启动“科技创新2030—‘新一代人工智能’”重大项目，意在鼓励国内各大科研院所、高等院校和企业对人工智能进行深入研究与探索。伴随着人工智能的蓬勃发展，以视觉目标跟踪、图像分类、目标检测等任务为代表的计算机视觉领域也获得了广泛的关注并在理论研究和实际应用方面取得了巨大的进展。
作为人工智能与计算机视觉领域最重要的问题之一，目标跟踪在无人驾驶系统、服务机器人和无人机等方面有着十分重要的应用。随着深度学习和传统机器学习相关理论的发展与完善，封闭固定环境下的目标跟踪已经达到了实际应用所需的性能要求。一些面向封闭环境的目标跟踪系统已经被用于现实生活中以保证人们的生命财产安全，比如家庭智能监控系统等。与封闭环境下的目标跟踪相比，开放环境下的目标跟踪具有更为重要的应用价值和社会需求。例如，对于无人驾驶系统来说，目标跟踪功能是其完成智能感知与决策所必不可少的组成部分。一个稳定且可靠的无人驾驶系统必须在开放环境中准确地跟踪到无人车周边的不同目标（如车辆、行人等）以便做出合理的决策来规避潜在的交通风险，进而保证无人车的行车安全。然而，开放环境下的目标跟踪是一个非常具有挑战性的任务并且依然存在着诸多技术难点和挑战，这极大地限制了各类目标跟踪方法的跟踪性能和在实际工程中的推广与使用[4]。因此，深入研究面向开放环境的鲁棒目标跟踪方法具有非常重要的理论研究意义和实际应用价值。
针对开放环境下的目标跟踪任务，已有许多机器学习方法[5]和深度网络模型[6]被研究以进一步提高跟踪性能。但是由于某些技术困难与挑战，这些方法无法获得理想的跟踪精度来完成从封闭环境到开放环境的有效跨越，也不能被真正地用于解决各种实际问题。具体来说，开放环境下的目标跟踪主要存在以下几个方面的难点和挑战：

1）复杂多变场景下的跟踪适应性问题。一个完整的目标跟踪系统主要包括跟踪模型和特征表达两个组成部分，其中跟踪模型主要负责在视频序列中确定目标位置，特征表达则选择合理的视觉特征对目标进行表示。在开放环境下，目标跟踪系统需要在复杂多变的跟踪场景中成功地跟踪到目标。因此，为了追求更好的跟踪性能，主流的目标跟踪方法往往会学习到高度复杂的跟踪模型。以目前十分流行的相关滤波方法[7][8]为例，当利用高维深度特征进行特征表达时，该类方法的跟踪模型（岭回归模型）的参数数目能够达到109。高度复杂的跟踪模型极有可能导致机器学习中的过拟合问题，从而降低跟踪方法适应复杂跟踪场景的能力。也就是说，尽管这些方法可以在一些特定场景下准确地跟踪到目标，但是却无法在复杂多变的跟踪场景下成功地完成跟踪任务。例如，在无人驾驶系统中，高度复杂的跟踪模型将极大地降低跟踪方法的适应性，从而造成跟踪方法不能在复杂的交通场景中准确地跟踪到无人车周围的重要目标以规避交通风险。机器学习中的奥卡姆剃刀原则（Occam’s Razor）指出[9]：在所有可以选择的模型当中，能够很好地解释已知数据并且十分简单才是最好的模型。因此，如何降低跟踪模型复杂度以提高复杂场景下的跟踪适应性是开放环境下目标跟踪的一个重大挑战。
2）目标复杂的外观变化。在开放环境下，目标自身会发生十分复杂的外观变化，这极大地增加了跟踪方法取得理想性能的难度。目前主流的OTB数据集[10]和每年举办的VOT（Visual Object Tracking）[11]目标跟踪竞赛都把目标的外观变化分为多种类型，如：运动模糊、目标形变、光照变化、平面旋转等。值得一提的是，目标在某个时刻可能同时发生多种类型的外观变化，这将直接导致目标出现非常复杂的外观变化，进而限制跟踪方法在开放环境下的跟踪准确性。能否成功地应对目标复杂的外观变化将决定跟踪方法的跟踪性能和在实际问题中的应用前景。以刑事侦查中所依靠的天眼系统为例，如果目标在跟踪过程中所出现的复杂外观变化能够被有效地捕获，那么天眼系统将顺利地完成跟踪任务以确保社会安全，反之则系统可能在某一时刻跟丢目标，后果将十分严重。综上所述，如何捕获目标所出现的复杂外观变化以提高跟踪准确性是开放环境下目标跟踪的又一个重大挑战。
3）模型漂移问题。在跟踪过程中，目标不仅会经历复杂的外观变化，而且还会受到严重遮挡、嘈杂背景等外界干扰。由于目标跟踪方法中的跟踪模型需要被更新以考虑目标最新的外观变化[12]，所以目标所遇到的外界干扰可能会导致模型漂移问题。一旦模型漂移问题在跟踪过程中发生，跟踪方法将再也无法在复杂多变的场景中成功地跟踪到目标，这极大地降低了跟踪方法的跟踪性能。因此，理想的目标跟踪方法必须具有良好的鲁棒性以应对跟踪过程中的模型漂移问题。然而，目前主流的跟踪方法依然不具备良好的跟踪鲁棒性，比如在OTB和VOT数据集上达到顶级跟踪性能的SiamRPN++方法[13]经常在出现嘈杂背景和严重遮挡时发生模型漂移，进而导致跟踪失败的结果。对于ADAS系统（Advanced Driving Assistance System，高级驾驶辅助系统）和天眼系统等应用系统来说，能否抑制跟踪过程中的模型漂移问题也在很大程度上决定着这些系统的性能和应用前景。因此，如何抑制模型漂移问题以保证跟踪鲁棒性也开放环境下目标跟踪的一个重大挑战
针对上述挑战，本项目从模型精简与压缩、特征融合和跟踪框架设计等方面展开研究，解决开放环境下目标跟踪所面临的多个关键性科学问题，实现开放场景下的鲁棒目标跟踪。具体的研究工作包括：（1）拟提出基于稀疏约束的判别性跟踪模型，主要解决由于跟踪模型复杂度过高所引起的跟踪适应性问题；（2）拟提出基于时空上下文信息的动态多特征融合策略，重点解决目标所出现的复杂外观变化以提高开放场景下的跟踪准确性；（3）拟提出基于集成学习的跟踪方法，主要解决跟踪过程中的模型漂移问题以提高开放场景下的跟踪鲁棒性。值得一提的是，由于上述三个工作分别从跟踪模型、特征表达和跟踪框架角度出发以解决关键科学问题，因此工作（1）和（2）可以直接嵌入到工作（3）中以保证研究的整体性和统一性。
项目基于前期关于稀疏表达[14][15]、相关滤波[16][17]等方法的研究基础，结合集成学习、判别性跟踪模型、多特征融合和深度学习等相关方法和理论，拟提出基于稀疏约束的判别性跟踪模型、基于时空上下文信息的动态多特征融合策略和基于集成学习的跟踪方法，解决开放场景下目标跟踪任务中的跟踪适应性、目标复杂的外观变化和模型漂移等重要问题，提高跟踪方法的跟踪性能，实现开放环境下的鲁棒目标跟踪。本课题具有十分重要的理论研究意义和实际应用价值，相关研究成果将为目标跟踪的发展提供重要参考，并促进目标跟踪方法在不同领域中的现实应用。


\subsection{国内外研究现状及发展动态分析}
\subsubsection{类脑目标识别研究现状}
视觉目标跟踪是计算机视觉领域最重要和最有挑战性的任务之一，具备十分重要的应用价值。近年来，许多目标跟踪算法被提出以便在开放环境下取得理想的跟踪性能。总的来说，存在的目标跟踪方法可以被分为三大类：生成式跟踪方法、判别性跟踪方法和深度学习跟踪方法。
生成式方法将跟踪任务定义为一个相似性匹配问题，该类方法在跟踪过程中构建一个目标模型来表示目标所具有的特征，然后比较候选区域和目标模型的相似性来确定跟踪结果。最具代表性的生成式方法主要包括子空间方法[18][19]和稀疏表达方法[20][21]。其中子空间方法通过维度规约以获得一个低维子空间对目标进行表示，并且通过在子空间中比较所有候选目标的匹配度以完成对目标的跟踪。Ross等[18]提出了一种增量主成分分析方法（Incremental Principal Component Analysis）以准确地进行跟踪，该方法使用经典的PCA方法学习到一个关于目标的子空间，并在跟踪过程中对子空间进行增量地更新来考虑目标的外观变化。Sui等[19]首先利用跟踪过程中的跟踪结果学习一个全局子空间模型，然后学习一个基于像素级别的局部子空间模型，最后结合两个子空间模型以准确地跟踪目标。该方法可以利用全局模型和局部模型的优点以提升跟踪性能。与子空间方法有所不同，稀疏表达方法通过求解L1正则化模型完成对每个候选目标的稀疏编码，然后计算并比较所有候选的重构误差以选取最终的目标。Mei等[20]首次应用稀疏表达方法来解决目标跟踪问题，提出了流行的L1跟踪方法。L1方法利用粒子滤波采样多个候选目标，进而对每个候选进行稀疏编码以选取合适的候选作为跟踪结果。Qi等[21]提出了一种结构感知的局部稀疏编码算法来准确地跟踪目标。该方法考虑全局和局部稀疏限制对候选目标进行稀疏编码，采用快速迭代收缩阈值算法（Fast Iterative Shrinkage-thresholding Algorithm）来对模型进行求解。生成式跟踪方法在简单封闭环境下能够取得不错的跟踪精度和鲁棒性，但是该类方法在开放环境下的跟踪性能和速度都不太理想。
判别性方法把目标跟踪看作一个二分类问题（目标为正类，背景为负类），并且在线学习一个分类器来区分目标和背景。经典的判别性跟踪方法包括多实例学习[22]、P-N学习[23]、结构化支持向量机[24][25]和相关滤波[26][27][28]等。Babenko等[22]将训练样本以包的形式进行划分来训练分类器，进而提出了多实例学习方法（Multiple Instance Learning）以完成目标跟踪任务。Kalal等[23]将目标跟踪分为检测、跟踪和学习，并且设计了一个TLD（Tracking-Learning-Detection）框架以迭代地执行三种操作。为消除分类器训练过程中的样本标签问题，Hare等[24]基于机器学习中的结构化学习理论提出了一种结构化支持向量机（Structured Output SVM）跟踪方法。该方法能够准确地将目标和背景区分开来，具有更好的判别性。相关滤波方法[26][27][28]是近些年最成功和最有效的判别性跟踪方法。该类方法一方面利用信号处理领域的卷积操作以获取大量虚拟样本来训练高性能的滤波器，另一方面通过执行离散傅里叶变换（Discrete Fourier Transform，DFT）将空域内复杂的卷积操作转换为频域内简单的点击操作以进行高速的跟踪。 Bolme等[26]首先利用相关滤波方法来解决目标跟踪问题，并提出了MOSSE跟踪方法。MOSSE跟踪方法的跟踪速度达到每秒几百帧，满足了实时跟踪的要求。为了获得更好的跟踪性能，Henriques等[27]将高维HOG （Histogram of Oriented Gradient）特征嵌入到相关滤波框架，提出了十分流行的核相关滤波（Kernelized Correlation Filters）跟踪方法。判别性跟踪方法在开放环境下能够取得比生成式方法更好的跟踪性能和速度，也不存在深度学习方法那样的训练困难。然而，在追求更高的跟踪性能时，该类方法可能学习到高度复杂的跟踪模型，这限制了方法的对于复杂场景的适应能力。
显然，深度学习跟踪方法是目标跟踪领域最受关注的方法，并且达到了顶级的跟踪结果。主流的深度学习方法包括卷积神经网络[29][30][31]、孪生网络[32][33]、深度残差网络[34]等。卷积神经网络（Convolutional Neural Network）是传统神经网络的一种改进形式，它极大地减少了网络的参数数量。Nam等[29]利用大量带标注的视频训练一种多域网络（Multi-Domain Network）以准确地跟踪目标。该网络能够学习到关于目标的共享表示形式。Li等[30]设计了一个回归损失和一个排序损失来选择最有表示能力和最有效的卷积滤波器，进而获得目标感知的深度特征以表示目标。孪生网络（Siamese Network）方法的主要思想是将相似性度量学习应用到卷积神经网络来完成目标跟踪。Bertinetto等[32]首先提出了一种全卷积孪生网络来跟踪以完成跟踪任务。该网络在更大的范围内搜索目标，并且通过比较目标模板和候选的特征相似性来确定目标位置。为了处理目标剧烈的形变，Yu等[33]利用自注意力机制和跨越注意力机制以设计一个可形变孪生注意力网络。尽管基于深度网络的方法获得了理想的跟踪性能，但是大规模网络的训练不仅需要大量带标注的视频序列，而且存在着过拟合、难以收敛和容易陷入局部极小等问题。因此，许多研究工作[35][36][37]将深度特征引入到判别性跟踪方法（如支持向量机、相关滤波等）中以提高跟踪性能和规避训练问题。Hong等[35]从卷积网络中提取出深度特征以表示目标，并且学习支持向量机来进行目标跟踪。Danelljan等[36]学习一个连续卷积滤波器（Continuous Convolution Filters）以融合多个分辨率的视觉特征来获得更好的跟踪结果。通过利用深度特征，判别性跟踪方法可以取得理想的跟踪结果并且不存在训练方面的问题。但由于学习得到的跟踪模型具有很高的复杂度（例如：连续卷积滤波器[36]的模型参数可以达到109），这些方法的跟踪适应性会受到很大的影响。
由上可知，判别性方法和深度学习方法可以取得比生成式方法更优的跟踪性能，具有更好地应用前景。然而，在寻求更好的跟踪结果的同时，这些方法往往学习到高度复杂的跟踪模型。以判别性方法为例，当使用深度特征时，该类方法的模型复杂度将变得不可接受。高度复杂的跟踪模型严重降低了跟踪方法对复杂场景的适应性。因此，提出有效方法降低跟踪模型复杂度以提高开放场景下的跟踪适应性具有重要意义。

\subsubsection{多模态融合研究现状}
在开放环境下，目标在跟踪过程中会经历光照变化、剧烈形变和旋转等挑战，进而产生非常复杂的外观变化。复杂的外观变化极大地增加了跟踪方法准确跟踪到目标的难度，也降低了跟踪方法的准确性。怎样应对目标复杂的外观变化直接决定了跟踪方法的性能。研究表明，单一的视觉特征无法在复杂的跟踪场景下有效地建模目标外观。因此，融合多种视觉特来捕获目标复杂的外观变化以提高跟踪的准确性便成为一种可行的方案。
事实上，特征融合被广泛地应用于计算机视觉领域的多个任务，并且能够获得比单个特征更好的性能。对目标跟踪而言，前期的特征融合方法通常仅仅融合梯度（如：HOG特征）、颜色（如：ColorNames特征和RGB特征）和纹理（如：LBP特征）等传统手工特征。Hong等[38]利用稀疏表达和多任务学习设计了一种用以融合梯度、颜色和灰度等传统特征的联合稀疏跟踪方法。该方法将不同特征的稀疏编码作为不同的任务，利用混合范数约束多个特征具有类似的稀疏编码以联合地学习多个任务。Zhang等[39]通过梯度、纹理和颜色等特征训练多个支持向量机来从不同的角度对目标进行建模与跟踪。为有效地融合多个支持向量机的跟踪结果以确定目标位置，所提出的方法利用了一种基于信息熵的融合策略。基于流行的相关滤波框架，Li等[40]提出了一种SAMF 跟踪算法以融合对于目标跟踪任务十分有效的HOG特征和ColorNames特征以进行目标跟踪。通过融合上述两种视觉特征，SAMF方法可以取得更好的跟踪结果。通过分析颜色直方图和梯度特征之间具有互补性，Bertinetto等[41]设计了一种Staple跟踪算法融合颜色直方图特征和HOG特征以表示目标。Staple方法在跟踪精度与跟踪速度两方面都达到了不错的结果。由于不同的视觉特征能从不同的角度对目标外观进行表示，因此特征融合方法可以更好地捕获目标在跟踪过程中所发生的复杂外观变化，进而获得更优的跟踪性能。
考虑到深度特征具有很强的目标表示能力，许多特征融合方法尝试融合该类特征以进一步提高跟踪准确性。Ma等[42]将由卷积神经网络提取出来的深度特征融入到相关滤波框架以准确地跟踪目标。所提出的方法利用不同层次的特征学习多个相关滤波器，并且融合所有滤波器的相关响应以获得最终的跟踪结果。Zhang等[43]设计了一个多任务相关粒子滤波方法（Multi-task Correlation Particle Filter）以融合深度特征和传统特征来提升目标跟踪性能。该方法考虑多任务学习以挖掘多种视觉特征之间的潜在联系，进而实现有效的特征融合。为了融合具有不同分辨率的视觉特征, Danelljan等[44]提出了一种高效卷积跟踪器（Efficient Convolution Operators）。该跟踪方法基于相关滤波框架，融合梯度特征（HOG特征）、（ColorNames特征）和深度特征以准确地跟踪目标。Xu等[45]利用深度残差网络（ResNet-50网络）获得深度特征，并且结合梯度特征和颜色特征以完成跟踪任务。为准确地定位目标，所提出的方法首先利用能够捕获高层语义信息的深度特征以排除不可靠的候选目标，然后利用能够捕获目标细节的梯度和颜色特征来确定最终的目标。通过融合传统特征和深度特征以表示目标，特征融合方法可以获得不错的跟踪性能。然而当前的特征融合方法通常采用简单地串联或者由粗到精的策略融合多种特征，因此并不能充分利用不同特征的特性与优点以应对目标出现所的复杂外观变化。
事实上，传统特征（例如颜色、梯度等）和深度特征从不同的角度对目标进行表示并且具有不同的特点和优势，例如：前者可以表示目标的底层细节信息，而后者能够捕获目标的高层语义信息。因此，面对不同的跟踪场景，传统特征和深度特征应该被赋予不同的重要性来进行特征融合操作以捕获目标出现的复杂外观变化。提出高效的动态多特征融合方法以应对目标复杂的外观变化是提高跟踪准确性的关键。

\subsubsection{多专家机制与集成学习方法}
由于目标跟踪是一个在线学习任务，跟踪模型在跟踪过程中需要被更新以适应目标所出现的外观变化。但是当出现目标遮挡或嘈杂背景等外界干扰时，更新操作会严重地腐蚀跟踪模型，进而导致模型漂移问题。一旦模型漂移问题发生，跟踪方法将再也无法成功地跟踪到目标。为了确保跟踪方法的鲁棒性，必须设计有效的方法消除模型漂移问题。目前，用于应对模型漂移问题的跟踪方法主要有两类：多专家方法和集成学习方法。
基于多专家的跟踪方法通常构造多个专家抑制模型漂移问题，并且设计有效的选择机制以便从多个专家中选择出最好的一个来准确地确定目标。考虑到目标在跟踪过程中会出现多种外观模式，Nai等[16]学习多个相关滤波器以表示这些不同的外观模式。所提出的方法利用了一个两阶段选择策略来选择出一个合适的滤波器以定位目标，进而消除模型漂移问题和捕获目标复杂的外观变化。 Zhang等[46]设计了一种MEEM（Multi-Expert Entropy Minimization）跟踪算法提高跟踪的鲁棒性。MEEM算法通过保存跟踪过程中的跟踪器快照（Tracker Snapshot）以构成一个专家集合，然后通过最小熵准则从专家集合中挑选出一个用于确定目标状态的专家。Li等[47]利用多个跟踪器快照提出了一种HSME（Historical Snapshots Multi-Expert）跟踪方法以抑制模型漂移。该方法使用离散图建模多个专家之间的相互关联，并通过动态规划算法求解目标模型来得到一个精确解。Wang等[48]提出了一种多线索相关跟踪器（Multi-Cue Correlation Tracker）以利用多种视觉特征来有效地建模目标外观。MCCT方法首先通过不同的特征组合学习多个相关滤波器，然而计算单个滤波器的自相关分数和多个滤波器在跟踪过程中的互相关分数选择出一个最好的滤波器来准确地跟踪目标。基于多专家的跟踪方法在应对模型漂移问题上具有一定的优势，但是该类方法的稳定性却不足。此外，由于在跟踪过程中所利用的专家集合经常保留多个相似的专家，所以多专家跟踪方法存在专家选择方面的困难。
由于集成学习能够达到很好的泛化能力和鲁棒性，该类方法也被用于解决目标跟踪问题。和多专家方法相比，集成学习方法没有专家选择方面的问题，并且具备更好的稳定性。基于经典的Adaboost算法框架，Adrian等[49]在线学习多个弱分类器以构成一个强分类器来有效地区分背景和目标。所提出的跟踪方法可以在一定程度上消除模型漂移问题以提升跟踪鲁棒性。Bai等[51]将贝叶斯理论融入到集成学习框架当中，设计了一种随机集成跟踪器（Randomized Ensemble Tracker）来应对跟踪过程中的模型漂移和目标所出现的复杂外观变化。该算法把所有弱分类器的权值当成一个随机向量，然后通过求解该随机向量的后验分布来完成最后的跟踪任务。Gundogdu等[52]提出了一种基于树结构的集成学习算法以准确地跟踪目标。该方法首先学习多个相关滤波器并利用二叉树结构进行存储，然后将目标所出现的外观划分为多个类别且保证二叉树的每一个分支表示一种特定的外观，最后通过在二叉树中选取与目标当前外观最为相似的分支以确定最后的跟踪结果。为了获得满意的跟踪性能，基于集成学习的跟踪方法需要满足两个基本要求：首先，集成跟踪方法必须学习具有多样性的基分类器以确保最终的集成跟踪器能够应对复杂多变的跟踪场景；其次，所有基分类器必须被分配合理的权重以保证集成跟踪器能够消除跟踪过程中的模型漂移问题。然而，存在的基于集成学习的跟踪方法无法满足上述两个基本要求，这严重地限制了目标跟踪的鲁棒性和准确性。
由上可知，多样的基分类器和合理的权值是集成跟踪方法取得理想跟踪性能的关键，前者保证跟踪方法可以成功应对跟踪过程中多变的跟踪场景，后者则能确保跟踪方法有效抑制模型漂移问题。设计高效的基于集成学习的跟踪方法来消除模型漂移问题和对提高开放环境下目标跟踪的鲁棒性具有重要意义。

% 参考文献放这里
\begin{spacing}{1.3} % 行距
	\zihao{5} \songti   
	\bibliographystyle{gbt7714-nsfc}
	\bibliography{ref}  
	\vspace{11bp}
\end{spacing}



\NsfcSection{2}{项目的研究内容、研究目标，以及拟解决的关键科学问题}{（此部分为重点阐述内容）；}


\subsection{研究目标}
本项目以开放环境下的目标跟踪所面临的跟踪适应性、目标复杂的外观变化和模型漂移问题等挑战出发，从模型精简与压缩、特征融合和跟踪框架设计等方面展开研究，聚焦稀疏表达、判别性跟踪模型、动态多特征融合、集成学习和深度学习等相关理论与方法，重点突破基于稀疏约束的判别性跟踪模型、基于时空上下文信息的动态多特征融合策略、基于集成学习的跟踪方法等关键技术，研发面向开放环境的鲁棒目标跟踪算法，并利用标准视频数据集、ADAS高级智能驾驶辅助系统和真实无人车平台相结合的实验手段进行算法验证与测试，提高开放环境下的跟踪适应性、准确性和鲁棒性，设计具有良好性能的目标跟踪系统，推动目标跟踪在实际问题中的具体应用，为实现开放环境下的鲁棒目标跟踪提供新技术和新方法。图1展示了本项目的技术挑战、研究内容和关键科学问题。


\subsection{研究内容}

\subsubsection{基于多模态融合的类脑感知模型}
本项目针对开放环境下目标跟踪所存在的跟踪适应性问题，从模型精简与压缩的角度出发，拟提出基于稀疏约束的判别性跟踪模型以限制跟踪模型复杂度，提升跟踪方法在开放环境下的适应性。

\begin{itemize}
	\item 掌握模型精简与压缩方面的理论与方法，深入研究判别性跟踪方法（例如：支持向量机和相关滤波等）的跟踪模型复杂度对跟踪适应性的影响，了解稀疏表达方法在各类计算机视觉任务中的具体应用；
	\item 将稀疏表达思想引入到判别性跟踪模型当中，设计基于稀疏约束的判别性跟踪模型，研究高效的凸优化算法以正确地求解目标模型；
	\item 研究主流深度神经网络（例如：卷积神经网络、深度残差网络和孪生网络等）的特点与优势，选择合适的网络模型进行特征提取来有效地表示目标；
\end{itemize}

\subsubsection{基于全局工作空间理论的类脑规划决策模型}
本项目针对目标在开放环境下所出现的复杂外观变化，从特征融合的角度出发，拟提出基于时空上下文信息的动态多特征融合策略以有效地捕获目标所出现的复杂外观变化，提高跟踪方法的跟踪准确性。

\begin{itemize}
	\item 研究传统手工特征（例如：颜色特征、纹理特征和梯度特征）和深度特征在不同跟踪场景下的跟踪性能，分析各类特征在目标表示方面的优点和不足，调研主流特征融合方法的跟踪性能；
	\item 利用跟踪过程中的时空上下文信息评价不同特征的稳定性和判别性，动态地融合多种视觉特征来应对目标复杂的外观变化；
	\item 在上述基础之上，研究多模态信息融合方法以融合目标的多源信息（如深度信息，热红外信息），提高跟踪的准确性；
\end{itemize}


\subsubsection{基于运动皮层的类脑控制策略}
本项目针对跟踪过程中所出现的模型漂移问题，从跟踪框架的角度出发，拟提出基于集成学习的跟踪方法以消除模型漂移问题，提高跟踪方法在开放环境下的鲁棒性。

\begin{itemize}
	\item 分析模型漂移问题对跟踪性能的影响，研究各类跟踪算法（例如：生成式方法、判别性方法和深度学习方法）应对模型漂移问题的鲁棒性；
	\item 将集成学习框架作为跟踪框架，研究在线聚类算法和权值分配算法来获得具有多样性的弱分类器和合理的权值；
	\item 研究深度森林，深度boosting、深度梯度boosting等深度集成学习方法，进一步提高跟踪方法在复杂场景下的鲁棒性；
\end{itemize}

综上所述，本项目旨在从模型精简与压缩、特征融合和跟踪框架设计等角度展开研究以设计具有鲁棒性的目标跟踪方法。考虑到目标跟踪系统通常包括跟踪模型和特征表达两个组成模块，所以研究内容的前两点可以被嵌入到研究内容的第三点以保证项目研究的整体性。因此，本项目的研究工作具有系统性和整体性。


\subsection{拟解决的关键科学问题}

本项目以开放环境下的目标跟踪为研究对象，旨在设计鲁棒的目标跟踪方法以获得更好的跟踪精度，拟解决如下关键科学问题：

\subsubsection{基于多模态融合的类脑感知模型}
面向开放环境的目标跟踪方法需要具有良好的跟踪适应性以应对复杂多变的跟踪场景。然而，为了获得更好的跟踪性能，主流的跟踪方法（如：判别性跟踪方法和深度学习方法）往往会学习到高度复杂的跟踪模型。高度复杂的跟踪模型不仅计算代价大，而且容易导致过拟合问题。因此，如何对高度复杂的跟踪模型进行精简与压缩以提高模型的跟踪适应性是提高本项目拟解决的关键科学问题之一，也是提升开放环境下的跟踪性能所必须要解决的困难。

\subsubsection{基于全局工作空间理论的类脑规划决策模型}
目标在开放环境下不可避免地会出现光照变化、平面旋转、剧烈形变和运动模糊等多种外观变化，进而产生十分复杂的外观变化。复杂的外观变化大大地增加了跟踪方法成功跟踪目标的难度，降低了跟踪方法开放环境下的跟踪准确性。研究表明，单个视觉特征往往不能有效地捕获目标所出现的复杂外观变化。考虑到不同的视觉能够从不同的角度对目标进行表示，融合多种视觉特征便成为应对目标复杂外观变化的一种可行方案。因此，如何设计具有强表示能力的多特征融合以捕获目标复杂的外观变化也是本项目拟解决的关键科学问题。

\subsubsection{基于运动皮层的类脑控制策略}
目标在跟踪过程中会受到严重遮挡、嘈杂背景等外界干扰，进而引发模型漂移问题。模型漂移问题会导致跟踪失败，使得跟踪方法无法再准确地跟踪到目标。一个鲁棒的目标跟踪系统必须具有良好的鲁棒性以抑制模型漂移问题。事实上，仅仅研究目标跟踪系统中的跟踪模型或特征表达部分无法有效地消除模型漂移问题。因此，本项目从跟踪框架的角度出发以考虑跟踪的鲁棒性问题。如何设计具有强鲁棒性的跟踪框架以消除模型漂移问题是本项目拟解决的又一关键科学问题。





\NsfcSection{3}{拟采取的研究方案及可行性分析}{（包括研究方法、技术路线、实验手段、关键技术等说明）；}

\subsection{研究方法与技术路线}
该课题主要包括三个阶段：类脑图像识别的设计分析和建模、类脑跟踪的机理研究和仿真、类脑感知融合探索和研究。
本项目结合理论研究与实际应用，针对开放环境下的目标跟踪所面临的跟踪适应性问题、目标复杂的外观变化和模型漂移等挑战，采用计算机视觉、机器学习、深度学习、稀疏表达、判别性跟踪模型、集成学习、多特征融合等方法、技术与理论，考虑公开视频数据集、ADAS智能驾驶辅助系统和真实无人车平台相结合的验证与测试方法，研究基于稀疏约束的判别性跟踪模型、基于时空上下文信息的动态多特征融合策略和基于集成学习的跟踪方法，提高开放环境下的跟踪性能。
以开放环境下的目标跟踪为研究对象，本项目的研究工作分为相关问题分析、模型算法设计和方法验证测试三个层面（图2为技术路线）：
（1）相关问题分析：利用当前主流的目标跟踪系统和公开视频数据集，深入分析跟踪适应性问题、目标复杂的外观变化与模型漂移等挑战对目标跟踪算法性能和鲁棒性的影响。此外，结合计算机视觉、机器学习等相关理论方法与申请人前期关于目标跟踪课题所做的研究工作，从跟踪模型精简与压缩、特征融合和跟踪框架设计等方面展开具体的研究工作。具体来说，从跟踪模型精简与压缩的角度研究跟踪适应性问题的解决方法、从特征融合的角度研究目标复杂的外观变化的解决方法、从跟踪框架设计的角度研究模型漂移问题的解决方法。
（2）模型算法设计：基于对关键性科学问题的详细分析与申请人在目标跟踪、深度学习、判别性模型、稀疏表达、集成学习、多特征融合等方面的相关工作，设计鲁棒跟踪方法解决（1）中的科学问题以获得更好的跟踪效果。其中，提出基于稀疏约束的判别性跟踪模型解决跟踪适应性问题，提出基于时空上下文信息的动态多特征融合策略捕获目标复杂的外观变化，提出基于集成学习的跟踪方法应对跟踪过程中的模型漂移问题。
（3）方法验证测试：为有效地评估（2）中所设计的目标跟踪方法，采用开放环境下的标准视频数据集、项目申请人参加研发的ADAS高级智能驾驶辅助系统与真实无人车平台进行测试和验证，分析跟踪算法的跟踪性能、优势和不足，增强跟踪算法在实际应用中的可行性。
综上所述，本项目重点研究开放环境下的目标跟踪，以跟踪适应性、目标复杂的外观变化、模型漂移问题等科学问题为驱动，采用“相关问题分析模型算法设计方法验证测试”的技术路线，研究“基于稀疏约束的判别性跟踪模型、基于时空上下文信息的动态多特征融合策略、基于集成学习的跟踪方法”三个方面的相关理论与关键技术。


\subsection{关键技术}

\subsubsection{基于多模态融合的类脑感知模型}
第一阶段，根据大脑皮层视觉中腹侧流通路的研究，如图1所示，涉及目标识别的通路主要包括初级视觉皮层V1、纹外皮层V2和V4、颞枕皮层TEO、下颞皮层IT，其中下颞皮层时目标识别的主要区域。参照腹侧流通路的解剖结构，利用卷积和循环结构，构建大脑对齐的深度模型，可以设计相对应的类脑图像识别网络，并获得输入图像在深度网络中的激活响应，研究图像识别功能在大脑皮层和深度神经网络中表现的激活相似性，同时进行进行神经度量和行为度量，利用类脑识别分数进行深度神经网络和大脑的对比，并利用设计并训练好的类脑模型，确定识别的图像模式分别在深度网络和大脑皮层中的位置，寻找图像识别的类别信息在深度网络中的表征模式与大脑中的激活特征之间的映射关系。


\subsubsection{基于全局工作空间理论的类脑规划决策模型}
第二阶段，参照人类大脑皮层中背侧流通路进行类脑跟踪的机理研究和仿真，通过量化的大脑相似性分数，并利用所获得的皮层解剖知识来启发类脑跟踪模型的设计。如图2所示，类脑跟踪模型包括映射到人脑的四个区域：初级视觉皮层，中颞和上颞内侧区、额叶视区和脑干/小脑 。初级视觉皮层使用经典的卷积层进行建模，执行预处理以减少数据大小。中颞区和上颞内侧区使用动态滤波器网络进行建模，额叶视区使用循环神经网络进行建模。对于最开始的输入刺激，神经网络的输出表示大脑对齐模型中的深度神经网络的激活响应和边界框，而大脑皮层在跟踪时的表示是大脑皮层的激活和眼睛注视的位置，同时类脑跟踪模型显示了计算机视觉跟踪性能与大脑跟踪响应之间的相似性关系。为了比较模型，通过检查深度神经网络中各层的激活来构建到皮层的映射，以便能够很好地理解特定大脑皮层区域中的激活，理想情况下，这种大脑皮层激活不需要多余参数的类脑模型所预测得到，将会降低传统深度跟踪模型的冗余度。因此类脑跟踪模型由卷积层、动态滤波网络、长短时记忆网络和全连接层四个神经网络模块组成，它们类比于大脑平滑跟踪皮层通路中的初级视觉皮层、中颞区和上颞内侧区、额叶视区、脑干/小脑，其中脑干/小脑是运动预测器，将额叶视区的输出转换为相应的运动响应。这种明确的大脑分区思想是设计类脑跟踪模型重要的一步，并且致力于寻找更通用的网络结构。整个模型包括在皮层区域没有差异的神经网络，以及各种改进类脑跟踪模型的连接。并在此基础上对比激活和行为之间的相似性。
同时时在类脑跟踪模型的基础之上分析模型的动态响应和大脑皮层对运动的响应之间的相似性或相关性。并加入第一阶段类脑图像识别模型，类比于大脑皮层中腹侧流和背侧流之间的相互连接和影响，进一步提高视觉皮层的建模精度，以便更好地适应真实和复杂的动态场景，提高类脑模型的跟踪精度和类脑的真实性。


\subsubsection{基于运动皮层的类脑控制策略}
在之前工作的基础之上，考虑大脑中其他模态的信息和视觉信息的相互作用，类比于人类感知中的“通感”。考虑在人所接收的所有感知信息中，听觉信息是仅次于视觉信息的第二大感知源，两者占人所有感知信息的百分之九十以上，所以在建模类脑的多模态感知时主要考虑人类的听觉。听觉识别通路主要包括初级听觉皮层A1、带状区Belt、伞状区PB、中颞/下颞区，并利用卷积神经网络和循环网络为基本结构，模拟人脑处理模式，构建大脑对齐的类脑模型，进行激活和行为之间的对比，包括大脑激活和神经网络激活之间的相似性、网络预测的音频类别和人类动作选择之间的相似性。
同时由于听觉识别的核心区域中颞/下颞区和第一阶段中的目标识别的下颞核心区有重叠部位，为视觉和听觉的融合处理提供了神经解剖基础，可以进一步在图像识别模型和音频识别模型的基础之上设计视觉/听觉融合模块，进行高层特征级别融合，有望进一步提高处理复杂环境输入的能力和提升类脑模型的预测能力。
在进行类脑模型的研究过程中，期待逐步建立一套科学合理的类脑评价指标用于评价所设计的类脑深度神经网络模型和人脑大脑处理信息的相似程度，在类脑图像识别中表现为图像分类和人进行图片识别时选择的相似性，在类脑跟踪中表现为深度神经网络输出的定位框和以人眼中央凹为中心的注意力范围，在感知融合中表现为在融合其他类型信息的复杂条件下模型的预测输出和人行为的相似性。该指标不仅衡量和模型的预测输出和人类行为之间的相似性，而且还衡量模型面对相同的输入刺激，各个中间层的激活响应和人类大脑皮层各个区域的激活（血液动力学响应或者脑电信号等）之间的相似性或相关性，实现从模型结构、皮层激活响应、人类行为等方面进行综合的类脑相似性解释。


\subsection{实验手段}
本项目主要采用标准数据集、ADAS高级智能驾驶辅助系统和真实无人车平台相结合的实验方法，分析拟提出的跟踪方法在开放环境下的跟踪性能。实验主要包括基于标准数据集的验证、基于ADAS系统的测试和基于真实无人车平台的测试等三个方面。

\subsubsection{基于标准数据集的验证}
当前已有许多具有大规模的标准数据集被发布以推动目标跟踪的发展，例如OTB、VOT、UAV123、TC-128和LaSOT等。这些数据集都是在复杂多变的场景下所采集到的，十分具有挑战性。以权威的OTB和VOT为例，OTB数据集由100个视频所组成，包含了58000多帧图片，视频集捕获了复杂场景下的行人、车辆、动物等多种目标，VOT数据主要用于一年一度的视觉目标跟踪竞赛，该数据集每年都会被重新标注和更新来提高数据集的准确性和竞赛难度，目前主要包括60个具有高难度的视频。本项目申请人所在的实验室拥有由多台服务器和PC机所组成的计算平台，该计算平台上安装了Caffe、Keras和Tensflow等深度学习框架，下载了OTB、VOT、UAV123、TC-128和LaSOT等视频数据集，并配置了不同数据集的测试程序。值得一提的是，由于不同数据集采用不同的性能指标以评估跟踪算法的结果，因此测试程序可以有效地验证跟踪算法在不同数据集上的跟踪精度。通过在大规模的标准数据集进行综合性实验能够可靠地验证拟提出的跟踪算法在开放环境下的跟踪性能。

\subsubsection{基于ADAS高级智能驾驶辅助系统的测试}
项目申请人在攻读博士学位期间作为团队的骨干成员参与了ADAS高级智能驾驶辅助系统的研发工作，主要负责环境感知模块的主要功能与相关算法的设计。具体来说，ADAS系统中的环境感知模块主要包括行人与车辆检测与跟踪、交通标志检测与跟踪和车道线检测等任务。图15展示了与本项目研究相关的行人与车辆检测与跟踪和交通标志检测与跟踪的定性结果。因此，可以将本项目拟提出的目标跟踪算法移植到ADAS系统中，通过利用ADAS系统平台测试跟踪方法的性能。

\subsubsection{基于真实无人车平台的测试}
本项目申请人所在的团队与长沙智能驾驶研究院存在合作关系，具有无人车一台。无人车平台上装有摄像头、激光雷达、毫米波雷达和组合导航等多个传感设备。图16展示了无人车平台和团队成员进行实车测试的情况。因此，本项目具有在真实无人车平台上进行实车测试的条件，将来有可能利用该无人车平台验证本项目拟提出的跟踪算法在开放环境下的跟踪性能。


\subsection{可行性分析}
（1）研究目标明确，技术路线清晰。本项目主要研究面向开放环境的鲁棒目标跟踪方法。具体来说，以目标跟踪所存在的跟踪适应性、目标复杂的外观变化和模型漂移等问题为驱动，基于“相关问题分析——模型算法设计——方法验证测试”的技术路线，利用深度学习、机器学习、稀疏表达、判别性模型、多特征融合和集成学习等方法与理论，拟提出基于稀疏约束的判别性跟踪模型、基于时空上下文信息的动态多特征融合策略和基于集成学习的跟踪方法以提高开放环境下的跟踪适应性、准确性和鲁棒性，进而提高开放环境下的跟踪性能。
（2）项目申请人具有一定的研究基础。如上所述，关于该课题三个阶段已有一定的研究基础，包括基本的类脑图像识别模型和评价指标，可以要在此基础上基于已有的人脸识别刺激数据和对应的多模型神经成像数据，利用人脸识别任务分析类脑模型和深度神经网络对相同图像刺激所产生的激活之间的相似性或关联关系，以及进一步分析负责人脸识别区的梭状回和负责目标识别区的下颞回之间的联系和区别。
本课题组已设计和测试类脑跟踪中背侧通路的建模和仿真，建立初步的运动感知模型，定量化验证中颞区和上颞内侧区和动态滤波网络激活的相似性，并在公开数据集上进行了仿真和验证，可以在此基础上加入图像识别的腹侧流模型，进一步研究背侧流和腹侧流共同作用下动态环境的建模和仿真。
类脑感知融合研究中已对类脑听觉皮层模型进行了初步建模，在音乐流派分类数据集合对应的核磁共振数据集上进行了响应分析，需要在此基础上分析深度模型激活和大脑皮层激活之间的相似性，并加入第一阶段腹侧流通路的建模，以进一步提高类脑模型的鲁棒性，提升模型的激活和行为的预测精度。



\NsfcSection{4}{本项目的特色与创新之处；}{}

该类脑研究是可解释深度神经网络的一个很好地解决方案，设计大脑皮层对齐的类脑模型不仅可以设计出符合生物学解剖规律的深度神经网络，利用神经科学的原理来解释所设计的深度网络模型，有望解决深度神经网络“黑盒”的问题，还可以精简模型的层数，减少模型冗余，有利于工程化部署，加快计算机视觉算法的产业化落地。      同时利用设计并训练好的类脑深度神经网络探索脑机接口的应用和人产生视觉概念乃至意识的神经相关物，利用已经比较成熟的高性能计算机和深度学习算法，解决神经科学实验条件受限的不足，解决深度学习领域模型的复杂度越来越高、可解释性越来越差的问题。


\NsfcSection{5}{年度研究计划及预期研究结果}{（包括拟组织的重要学术交流活动、国际合作与交流计划等）。}

本项目以开放环境下的目标跟踪为研究对象，旨在设计鲁棒的目标跟踪方法以获得更好的跟踪精度，拟解决如下关键科学问题：




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\NsfcChapter{（二）研究基础与工作条件}{}


\NsfcSection{1}{研究基础}{（与本项目相关的研究工作积累和已取得的研究工作成绩）；}

无

\NsfcSection{2}{工作条件}{（包括已具备的实验条件，尚缺少的实验条件和拟解决的途径，包括利用国家实验室、国家重点实验室和部门重点实验室等研究基地的计划与落实情况）；}

无

\NsfcSection{3}{正在承担的与本项目相关的科研项目情况}{（申请人和项目组主要参与者正在承担的与本项目相关的科研项目情况，包括国家自然科学基金的项目和国家其他科技计划项目，要注明项目的名称和编号、经费来源、起止年月、与本项目的关系及负责的内容等）；}

无

\NsfcSection{4}{完成国家自然科学基金项目情况}{（对申请人负责的前一个已结题科学基金项目（项目名称及批准号）完成情况、后续研究进展及与本申请项目的关系加以详细说明。另附该已结题项目研究工作总结摘要（限500字）和相关成果的详细目录）。}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

无

\NsfcChapter{（三）其他需要说明的问题}{}

\NsfcSection{1}{}{申请人同年申请不同类型的国家自然科学基金项目情况（列明同年申请的其他项目的项目类型、项目名称信息，并说明与本项目之间的区别与联系）。}

无

\NsfcSection{2}{}{具有高级专业技术职务（职称）的申请人或者主要参与者是否存在同年申请或者参与申请国家自然科学基金项目的单位不一致的情况；如存在上述情况，列明所涉及人员的姓名，申请或参与申请的其他项目的项目类型、项目名称、单位名称、上述人员在该项目中是申请人还是参与者，并说明单位不一致原因。}

无

\NsfcSection{3}{}{具有高级专业技术职务（职称）的申请人或者主要参与者是否存在与正在承担的国家自然科学基金项目的单位不一致的情况；如存在上述情况，列明所涉及人员的姓名，正在承担项目的批准号、项目类型、项目名称、单位名称、起止年月，并说明单位不一致原因。}

无

\NsfcSection{4}{}{其他。}


\end{document}
